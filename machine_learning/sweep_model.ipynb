{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from model.make_model import *\n",
    "\n",
    "wandb.init(project=\"dtu-course\", entity=\"freja-thoresen\")\n",
    "\n",
    "figure_path = '../figures/'\n",
    "\n",
    "use_cuda=False\n",
    "\n",
    "cuda=False\n",
    "if torch.cuda.is_available():\n",
    "  dev = \"cuda:0\"\n",
    "  cuda=True\n",
    "else:\n",
    "  dev = \"cpu\"\n",
    "device = torch.device(dev)\n",
    "\n",
    "sequence_length = 10\n",
    "epochs = 5 # 1000 epochs\n",
    "learning_rate = 0.002\n",
    "lstm_dropbout = 0.2\n",
    "linear_dropout = 0.2\n",
    "input_size = 1 # number of features\n",
    "lstm_hidden_size = 20 # number of features in hidden state\n",
    "linear_hidden_size = 40 # number of features in hidden state\n",
    "num_layers = 2 # number of stacked lstm layers\n",
    "num_classes = 1 # number of output classes\n",
    "no_batches = 100\n",
    "no_files = 100 # no. data files\n",
    "\n",
    "wandb.config = {\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"sequence_length\": sequence_length,\n",
    "    \"epochs\": epochs,\n",
    "    \"input_size\": input_size,\n",
    "    \"lstm_hidden_size\": lstm_hidden_size,\n",
    "    \"linear_hidden_size\": linear_hidden_size,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"no_batches\": no_batches,\n",
    "    \"no_files\": no_files,\n",
    "    \"lstm_dropbout\": lstm_dropbout,\n",
    "    \"linear_dropout\": linear_dropout,\n",
    "    \"num_classes\": num_classes,\n",
    "    \"input_size\": input_size\n",
    "}\n",
    "\n",
    "sweep_config = {\n",
    "    'name': 'model-sweep',\n",
    "    'method': 'grid',\n",
    "    'metric': {\n",
    "        'name': 'training_loss',\n",
    "        'goal': 'minimize'\n",
    "    }\n",
    "}\n",
    "parameters_dict = {\n",
    "    'learning_rate': {\n",
    "        'value': 0.0002\n",
    "    },\n",
    "    'sequence_length': {\n",
    "        'value': 10\n",
    "    },\n",
    "    'epochs': {\n",
    "        'value': 40\n",
    "    },\n",
    "    'input_size': {\n",
    "        'value': input_size\n",
    "    },\n",
    "    'lstm_hidden_size': {\n",
    "        'values': [20, 40, 60]\n",
    "    },\n",
    "    'linear_hidden_size': {\n",
    "        'values': [20, 40, 60]\n",
    "    },\n",
    "    'num_layers': {\n",
    "        'values': [2, 3]\n",
    "    },\n",
    "    'no_batches': {\n",
    "        'value': 100\n",
    "    },\n",
    "    'no_files': {\n",
    "        'value': no_files\n",
    "    },\n",
    "    'lstm_dropbout': {\n",
    "        'values': [0.2, 0.4]\n",
    "    },\n",
    "    'linear_dropout': {\n",
    "        'values': [0.2, 0.4]\n",
    "    },\n",
    "    'num_classes': {\n",
    "        'value': num_classes\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"dtu-course\")\n",
    "\n",
    "def sweep():\n",
    "    with wandb.init() as run:\n",
    "        config = wandb.config\n",
    "        lstm, criterion, optimizer = make_model(config)\n",
    "        train_model(lstm, criterion, optimizer, config)\n",
    "wandb.agent(sweep_id, function=sweep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "ml",
   "language": "python",
   "display_name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}