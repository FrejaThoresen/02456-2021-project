{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e17b0a6d-76f3-4e3d-aa0b-92c2d65b0fee",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LSTM using raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d011c513-97d6-4fcf-a197-66afdf9a2081",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd7da1e-110d-41ce-824a-db83e46c5a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** FP-modules version 2.10.13 ***\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Sigmoid, Softmax\n",
    "from labelled_data.tools.load_data import data_loader\n",
    "from labelled_data.tools.load_data import data_generator\n",
    "figure_path = '/home/thoresen/Code/deep_learning/02456-2021-project/figures/'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Raw data or chunked data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "chunks = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "e522b47c-4d54-4804-aca9-975fde0dcc5b",
   "metadata": {},
   "source": [
    "# Define data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X_train, X_test, X_valid, y_train, y_test, y_valid = data_loader(chunks=chunks, no_files=10)\n",
    "train_gen = data_generator(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data, labels = train_gen.__next__()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "db0ec1d0-7d18-49c4-b535-1cf5bd710ab3",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_classes = num_classes #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True) #lstm\n",
    "        #self.dropout = nn.Dropout(0.2)\n",
    "        self.linear_out = nn.Linear(hidden_size, num_classes) #fully connected last layer\n",
    "        self.sigmoid = Sigmoid()\n",
    "        #self.softmax = Softmax()\n",
    "\n",
    "    def forward(self,x):\n",
    "        # Propagate input through LSTM\n",
    "        x, (h, c) = self.lstm(x) #lstm with input, hidden, and internal state\n",
    "        x = x.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        #x = self.dropout(x)\n",
    "        x = self.linear_out(x) #first Dense\n",
    "        out = self.sigmoid(x) #Final Output\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "a9acabf4-99dc-4b4c-a65b-834f9ae9e4f7",
   "metadata": {},
   "source": [
    "## Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a45ec70d-622a-46b6-8252-99c60249d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50 # 1000 epochs\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = 1 # number of features\n",
    "hidden_size = 40 # number of features in hidden state\n",
    "num_layers = 2 # number of stacked lstm layers\n",
    "\n",
    "num_classes = 1 # number of output classes\n",
    "\n",
    "no_files = 1 # no. data files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97753243-616e-4c55-be2d-ef0586931a85",
   "metadata": {},
   "source": [
    " ## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae8f9f2d-388d-4cf9-91a7-bd20c0577926",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(num_classes, input_size, hidden_size, num_layers) #our lstm class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b1105e-b80e-4d22-8f84-52082347205b",
   "metadata": {},
   "source": [
    "## Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64a8e622-4d88-49b3-ae37-2e231d8b32fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss() # cross validation\n",
    "#criterion = torch.nn.MSELoss() # cross validation\n",
    "\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.SGD(lstm.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b2df0a-ea50-47e3-9f11-4a9ddeb35953",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def evaluate_result(output):\n",
    "    output[output > 0.7] = 1.\n",
    "    output[output < 0.7] = 0.\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab454a5-1235-4504-92f0-04632aaae55c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating file number 0\n"
     ]
    }
   ],
   "source": [
    "epoch_training_loss = []\n",
    "epoch_validation_loss = []\n",
    "epoch_training_acc = []\n",
    "epoch_validation_acc = []\n",
    "\n",
    "X_train, X_test, X_valid, y_train, y_test, y_valid = data_loader(chunks=chunks, no_files=no_files)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  training_loss = 0\n",
    "  validation_loss = 0\n",
    "  training_correct = 0\n",
    "  training_all = 0\n",
    "  validation_correct = 0\n",
    "  validation_all = 0\n",
    "\n",
    "  train_gen = data_generator(X_train, y_train)\n",
    "  test_gen = data_generator(X_test, y_test)\n",
    "  valid_gen = data_generator(X_valid, y_valid)\n",
    "\n",
    "  dict = {\n",
    "      'no_train' : len(X_train),\n",
    "      'train': train_gen,\n",
    "      'no_test' : len(X_test),\n",
    "      'test': test_gen,\n",
    "      'no_valid' : len(X_valid),\n",
    "      'valid': valid_gen,\n",
    "  }\n",
    "\n",
    "  for _ in range(len(X_valid)):\n",
    "      print(f'validating file number {_}')\n",
    "\n",
    "      data, labels = valid_gen.__next__()\n",
    "      if chunks:\n",
    "        data = data[int(len(data)*0.25):int(len(data)*0.75)]\n",
    "        labels = labels[int(len(labels)*0.25):int(len(labels)*0.75)]\n",
    "      lstm.eval()\n",
    "      outputs = lstm.forward(data) #forward pass\n",
    "\n",
    "      #loss = criterion(d, labels.flatten().to(torch.long))\n",
    "      loss = criterion(outputs, labels)\n",
    "      print(loss.shape)\n",
    "      loss.backward() #calculates the loss of the loss function\n",
    "      validation_loss += loss.item()\n",
    "\n",
    "      validation_correct += (evaluate_result(outputs) == labels).float().sum()\n",
    "      validation_all += len(labels)\n",
    "\n",
    "  for _ in range(len(X_train)):\n",
    "      print(f'training file number {_}')\n",
    "      data, labels = train_gen.__next__()\n",
    "      if chunks:\n",
    "        data = data[int(len(data)*0.25):int(len(data)*0.75)]\n",
    "        labels = labels[int(len(labels)*0.25):int(len(labels)*0.75)]\n",
    "      lstm.train()\n",
    "      outputs = lstm.forward(data) #forward pass\n",
    "\n",
    "      # obtain the loss function\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward() #calculates the loss of the loss function\n",
    "      training_loss += loss.item()\n",
    "\n",
    "      training_correct += (evaluate_result(outputs) == labels).float().sum()\n",
    "      training_all += len(labels)\n",
    "\n",
    "      optimizer.step() #improve from loss, i.e backprop\n",
    "      optimizer.zero_grad() #caluclate the gradient, manually setting to 0\n",
    "  validation_acc = validation_correct / validation_all\n",
    "  training_acc = training_correct / training_all\n",
    "  if epoch % 10 == 0:\n",
    "    print(\"Epoch: %d, training loss: %1.5f, validation loss: %1.5f, training acc: %1.5f, , validation acc: %1.5f\" % (epoch, training_loss/len(X_train), validation_loss/len(X_valid), training_acc, validation_acc))\n",
    "\n",
    "  epoch_validation_loss.append(validation_loss/len(X_valid))\n",
    "  epoch_validation_acc.append(validation_acc)\n",
    "  epoch_training_loss.append(training_loss/len(X_train))\n",
    "  epoch_training_acc.append(training_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_gen = data_generator(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,5))\n",
    "data, labels = train_gen.__next__()\n",
    "data = data.detach().numpy()[:,0,0]\n",
    "#plt.plot(data[int(len(data)*0.25):int(len(data)*0.75)])\n",
    "plt.plot(data)\n",
    "\n",
    "if labels.sum() > 0:\n",
    "#plt.plot(labels[int(len(data)*0.25):int(len(data)*0.75)]*1330)\n",
    "    plt.plot(labels*1330)\n",
    "#plt.gca().set_ylim([1300,1500])\n",
    "#plt.gca().set_xlim([1610000,len(data)-860000])\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0, len(epoch_validation_loss)-1, len(epoch_validation_loss)), epoch_validation_loss, label='validation loss')\n",
    "plt.plot(np.linspace(0, len(epoch_training_loss)-1, len(epoch_training_loss)), epoch_training_loss, label='training loss')\n",
    "plt.gca().set_ylabel('Loss')\n",
    "plt.gca().set_xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.savefig(figure_path + 'validation.png', bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0, len(epoch_validation_acc)-1, len(epoch_validation_acc)), epoch_validation_acc, label='validation acc')\n",
    "plt.plot(np.linspace(0, len(epoch_training_acc)-1, len(epoch_training_acc)), epoch_training_acc, label='training acc')\n",
    "plt.gca().set_ylabel('Accuracy')\n",
    "plt.gca().set_xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.savefig(figure_path + 'accuracy.png', bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(lstm.state_dict(), '../models/model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "197123a2-9898-448a-9f63-798481c0a298",
   "metadata": {},
   "source": [
    "# Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09449e88-217c-491c-965d-a785019172e7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data, labels = test_gen.__next__()\n",
    "train_predict = lstm(data)#forward pass\n",
    "data_predict = train_predict.data.numpy() #numpy conversion\n",
    "data_predict[data_predict > 0.5] = 1\n",
    "data_predict[data_predict < 0.5] = 0\n",
    "\n",
    "dataY_plot = labels\n",
    "\n",
    "plt.figure(figsize=(10,6)) #plotting\n",
    "#plt.axvline(x=40000, c='r', linestyle='--') #size of the training set\n",
    "\n",
    "plt.plot(dataY_plot, label='Actual Data') #actual plot\n",
    "plt.plot(data_predict, label='Predicted Data') #predicted plot\n",
    "plt.title('Time-Series Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd04082b4c0ff6287cfc869426458e61daf0f96e72318d7dae093de8e29c11fa2fe",
   "language": "python",
   "display_name": "Python 3.8.5 64-bit ('fp_env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}